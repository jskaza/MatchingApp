{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using DataFramesMeta\n",
    "using GLM\n",
    "using CSV\n",
    "using StatsFuns\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# figure out how to read in types\n",
    "#data = vec(readdlm(\"coltypes.csv\", ',', String))\n",
    "#add type validations df::DataFrame\n",
    "# add exceptions for unique ids, etc\n",
    "# deal with missings\n",
    "# replacement\n",
    "# exact covariates\n",
    "# iptw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_dataset"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    make_dataset(df, _id_col_name, label_col_name, case, control, X)\n",
    "\n",
    "Return a DataFrame containg only the identifier column, label column, and covariates\n",
    "\n",
    "# Arguments\n",
    "- `df::DataFrame`: DataFrame to be manipulated\n",
    "- `_id_col_name:String`: Name of column containing _id's\n",
    "- `label_col_name:String`: Name of column containing labels\n",
    "- `case:String`: Label which represents case status\n",
    "- `control:String`: Label which represents control status\n",
    "\"\"\"\n",
    "function make_dataset(df, _id_col_name, label_col_name, case, control, X)\n",
    "    @subset!(df, $label_col_name  .== case .|| $label_col_name .== control)\n",
    "    df = df[:, vcat(_id_col_name, label_col_name, X)]\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_logit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    fit_logit(df, label)\n",
    "\n",
    "Return results from a logit model of `label` ~ rest of cols\n",
    "\"\"\"\n",
    "function fit_logit(df, _id_col_name, label_col_name, case)\n",
    "    df = @transform(df, $label_col_name = ($label_col_name .== case))\n",
    "    X = term.(names(df[:, Not([_id_col_name,label_col_name])]))\n",
    "    mod = glm(term(label_col_name) ~ foldl(+, X), df, Binomial(), LogitLink())\n",
    "    return mod\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "propensity_scores"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    propensity_scores(df, _id, labels, model, _id_col_name=\"_id\", label_colname=\"Label\", ps_col_name=\"propensityScore\")\n",
    "\n",
    "Add propensity score column to DataFrame\n",
    "\n",
    "# Arguments\n",
    "- `df::DataFrame`: DataFrame to append column\n",
    "- `_id:String`: Name of column containing _id's\n",
    "- `label_col_name:String`: Name of column containing labels\n",
    "- `case:String`: Label which represents case status\n",
    "- `control:String`: Label which represents control status\n",
    "\"\"\"\n",
    "function propensity_scores(df, model, _id_col_name, label_col_name; ps_col_name=\"propensityScore\")\n",
    "    ps = DataFrame(ps_col_name => predict(model))\n",
    "    return hcat(df[:, [_id_col_name,label_col_name]], ps)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "greedy_match (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function greedy_match(df,n,exact,replacement,_id_col_name,label_col_name,ps_col_name,case,control;caliper=\"calc\")\n",
    "    if caliper == \"calc\"\n",
    "        caliper = 0.2*std(logit.(df[:, ps_col_name]))\n",
    "    end\n",
    "    cases = @subset(df, $label_col_name .== case)\n",
    "    ps_cases = collect(enumerate(cases[:, ps_col_name]))\n",
    "    controls = @subset(df, $label_col_name .== control)\n",
    "    ps_controls = collect(enumerate(controls[:, ps_col_name]))\n",
    "    cases_to_drop = []\n",
    "    if replacement\n",
    "        controls_to_keep = []\n",
    "    end\n",
    "    for ps in ps_cases\n",
    "        diffs = (abs.(last.(ps_controls) .- last(ps)))\n",
    "        candidate_idx, candidate_diffs = (findall(x -> x <= caliper, diffs), diffs[diffs .<= caliper])\n",
    "        if length(candidate_idx) >= n\n",
    "            sorted_candidates = sort(collect(zip(candidate_idx, candidate_diffs)); by=last)\n",
    "            matches = sorted_candidates[1:n]\n",
    "            !replacement ? deleteat!(ps_controls, sort(first.(matches))) : append!(controls_to_keep, first.(matches))\n",
    "        elseif length(candidate_idx) > 0 && !exact\n",
    "            matches = candidate_idx\n",
    "            !replacement ? deleteat!(ps_controls, sort(candidate_idx)) : append!(controls_to_keep, first.(matches))\n",
    "        else\n",
    "            append!(cases_to_drop, first(ps))\n",
    "        end\n",
    "    end\n",
    "    if replacement\n",
    "        return vcat(cases[Not(cases_to_drop), :], controls[controls_to_keep, :])\n",
    "    else\n",
    "        return vcat(cases[Not(cases_to_drop), :], controls[Not(first.(ps_controls)), :])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merge_propensity_scores (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function merge_propensity_scores(df, ps_df, on)\n",
    "    return leftjoin(df, ps_df, on = on)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_matches (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function add_matches(df, match_df, _id_col_name, label_col_name)\n",
    "    to_add = df[findall(in(match_df[:, _id_col_name]), df[:, _id_col_name]), :]\n",
    "    to_add[:, label_col_name] = string.(to_add[:, label_col_name],\" Matched\")\n",
    "    return vcat(df, to_add)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function main(df,\n",
    "    _id_col_name,label_col_name,case,control,covariates,\n",
    "    n,n_exact,replacement;\n",
    "    ps_col_name=\"propensityScore\",caliper=\"calc\")\n",
    "\n",
    "    # df = CSV.read(file, DataFrame; delim = '\\t', header = true, stringtype = String)\n",
    "    ps_df = make_dataset(df, _id_col_name, label_col_name, case, control, covariates)\n",
    "    mod = fit_logit(ps_df, _id_col_name, label_col_name, case)\n",
    "    ps_df = propensity_scores(ps_df, mod, _id_col_name, label_col_name, ps_col_name=ps_col_name)\n",
    "    match_df = greedy_match(ps_df, n, n_exact, replacement, _id_col_name, label_col_name, ps_col_name, case, control, caliper=caliper)\n",
    "    df = merge_propensity_scores(df, ps_df, [_id_col_name, label_col_name])\n",
    "    return add_matches(df, match_df, _id_col_name, label_col_name)\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
